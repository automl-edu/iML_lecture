\begin{itemize}
\item What is more promising: (a) training a complex model and using post-hoc methods for explainability or (b) pre-processing data s.t. a interpretable model can be used?
\item For different stakeholders (ML engineer, business unit, lawyer/judge, ...), which of the interpretable model classes would be useful? If there is not one for all, how to deal with that problem in practice?
\item If a model is interpretable and the interpretation are accessible for users, would this imply that a trade secret is disclosed and therefore cannot be monetised?
\end{itemize}

